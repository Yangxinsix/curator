trainer:
  _target_: pytorch_lightning.Trainer
  devices: 1
  default_root_dir: .
  min_epochs: null
  max_epochs: 1000
  enable_model_summary: true
  profiler: null
  log_every_n_steps: 1
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  fast_dev_run: false
  overfit_batches: 0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  detect_anomaly: false
  precision: 32
  accelerator: auto
  num_nodes: 1
  deterministic: false
  inference_mode: false
  callbacks:
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ./model_path
    save_top_k: 1
    monitor: val_total_loss
    filename: best_model_{epoch}-{step}-{val_total_loss:.2f}
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: val_total_loss
    min_delta: 0.0
    patience: 200
    mode: min
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: epoch
  - _target_: curator.train.ExponentialMovingAverage
    decay: 0.995
    use_num_updates: true
  logger:
    _target_: pytorch_lightning.loggers.CSVLogger
    save_dir: ./logs
    name: curator-train
task:
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    amsgrad: true
    lr: 0.005
    eps: 1.0e-08
    betas:
    - 0.9
    - 0.999
    weight_decay: 0.0
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    factor: 0.8
    patience: 50
  _target_: curator.model.LitNNP
  scheduler_monitor: val_total_loss
  warmup_steps: 0
  outputs:
  - _target_: curator.model.ModelOutput
    name: energy
    loss_fn:
      _target_: torch.nn.MSELoss
    loss_weight: 1
    metrics:
      mae:
        _target_: torchmetrics.regression.MeanAbsoluteError
      rmse:
        _target_: torchmetrics.regression.MeanSquaredError
        squared: false
  - _target_: curator.model.ModelOutput
    name: forces
    loss_fn:
      _target_: torch.nn.MSELoss
    loss_weight: 1
    metrics:
      mae:
        _target_: torchmetrics.regression.MeanAbsoluteError
      rmse:
        _target_: torchmetrics.regression.MeanSquaredError
        squared: false
model:
  representation:
    _target_: curator.model.NequipModel
    cutoff: 4.0
    num_interactions: 4
    num_features: 32
    num_elements: 3
    species:
    - C
    - H
    - O
    num_basis: 8
    power: 6
    lmax: 2
    parity: true
    resnet: false
    nonlinearity_type: gate
    nonlinearity_scalars:
      e: silu
      o: tanh
    nonlinearity_gates:
      e: silu
      o: tanh
    convolution_kwargs:
      invariant_layers: 2
      invariant_neurons: 64
      use_sc: true
  _target_: curator.model.NeuralNetworkPotential
  input_modules:
  - _target_: curator.layer.PairwiseDistance
    compute_neighborlist: false
    compute_distance_from_R: true
  output_modules:
  - _target_: curator.layer.AtomwiseReduce
  - _target_: curator.layer.GradientOutput
    grad_on_edge_diff: false
    grad_on_positions: true
  - _target_: curator.layer.GlobalRescaleShift
data:
  _target_: curator.data.AtomsDataModule
  datapath: /home/xinyang/aspirin_dft.traj
  batch_size: 2
  compute_neighbor_list: true
  cutoff: 4.0
  val_batch_size: 8
  test_batch_size: 8
  num_train: 100
  num_val: 50
  num_test: null
  train_val_split: sequential
  shuffle: false
  num_workers: 1
  pin_memory: true
  species:
  - C
  - H
  - O
  avg_num_neighbors: auto
  atomic_energies: null
  normalization: true
  atomwise_normalization: false
  scale_forces: true
  transforms:
  - _target_: curator.data.TypeMapper
    species:
    - C
    - H
    - O
  - _target_: curator.data.Asap3NeighborList
    cutoff: 4.0
seed: 123
cfg: null
datapath: null
run_path: .
model_path: null
deploy_model: true
patience: 200
energy_weight: 1
forces_weight: 1
device: cuda
